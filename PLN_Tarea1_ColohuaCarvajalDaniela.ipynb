{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLN_Tarea1_ColohuaCarvajalDaniela.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuKjqH6iOyVWeRmjAMbCp1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielacarv/PLN/blob/main/PLN_Tarea1_ColohuaCarvajalDaniela.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpcNsmhyyaq"
      },
      "source": [
        "#**Tarea 1**\n",
        "\n",
        "# Alumna: Colohua Carvajal Daniela\n",
        "\n",
        "---\n",
        "\n",
        "* *Procesamiento de Lenguaje Natural*\n",
        "* *Facultad de Ingeniería, UNAM*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YZ0jWp7kWjD"
      },
      "source": [
        "\n",
        "\n",
        "**Objetivo:** Preprocesar un corpus a partir de métodos basados en lenguajes\n",
        "formales.\n",
        "\n",
        "\n",
        "1. **Escoger un corpus de cualquier idioma y de un tamaño mayor a 10 000\n",
        "tokens (se puede tomar este corpus de la paquetería nltk.corpus). Este\n",
        "corpus se usará a lo largo del curso.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsY8G5Nykpdk"
      },
      "source": [
        "\n",
        "\n",
        "> Para empezar, se importan todas las librerías que se utilizarán a lo largo del programa\n",
        "\n",
        "\n",
        "\n",
        "> 1.   *nltk.corpus* para obtener un corpus con las características solicitadas.\n",
        "2.   *string*, se utilizará para hacer la limpieza del corpus.\n",
        "3.   *stopwords* se utilizará para eliminar stopwords.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mceyJFwlj6jS"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zlFeri_Asde"
      },
      "source": [
        "\n",
        "> Al buscar los corpus que proporciona la librería antes mencionada, se eligió el corpus ***gutenberg***, que es una selección de textos del Proyecto Gutenberg. En la siguiente instrucción se descarga dicho corpus.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZLdYFNQBsLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a4ebd6-cc4c-4363-b223-033a6ddd4676"
      },
      "source": [
        "nltk.download('gutenberg') #Descarga corpus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z54fyVr3CJ8b"
      },
      "source": [
        "\n",
        "\n",
        "> Para hacer uso del corpus seleccionado se importa de la librería *nltk.corpus*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HOqBIHkJlKz"
      },
      "source": [
        "from nltk.corpus import gutenberg #Importa corpus"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrGf9sSCilo"
      },
      "source": [
        "\n",
        "\n",
        "> Debido a que el corpus gutenberg es una selección de textos, es necesario trabajar sólo con uno. A contnuación se listan los textos para elegir uno.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WxCJBL67-7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9238295a-d509-4310-91be-d3ffd4bd8f7d"
      },
      "source": [
        "files = nltk.corpus.gutenberg.fileids() #Lista textos del corpus\n",
        "print(files)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86OJiuwDF9u"
      },
      "source": [
        "\n",
        "\n",
        "> Después de ver la lista, se ha decidido ocupar el archivo *austen.txt*\n",
        "En el siguiente bloque de instrucciones:\n",
        "1.   Se asigna un nombre corto a este corpus\n",
        "2.   Para verificar que cumpla con los requisitos, se realiza un conteo de tokens.\n",
        "3.   Además, se cuntan los tipos \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te5J4KUOI5SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1c3a81-0841-4b45-f5cf-0d6eaed0626f"
      },
      "source": [
        "#Nombre corto para las palabras del corpus\n",
        "persuasion = nltk.corpus.gutenberg.words('austen-persuasion.txt') \n",
        "\n",
        "tokens = len(persuasion)     #Número de tokens\n",
        "tipos = len(set(persuasion)) #Número de tipos\n",
        "\n",
        "print('Numero de tokens:', tokens)\n",
        "print('Número de tipos:', tipos)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de tokens: 98171\n",
            "Número de tipos: 6132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07yWlJ0wEiZX"
      },
      "source": [
        "2. **Limpiar el corpus: eliminar signos de puntuación, de interrogación, admiración y elementos no léxicos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tgm4s930Kqz"
      },
      "source": [
        "\n",
        "\n",
        "> Para empezar, se pasan todos los caracteres a minpusculas para evitar conflictos. Para realizar esto, se hará uso del método *lower()* de la librería *string*. *lower()* se encarga de convertir la cadena a minúsculas, estos resultados se guardan en una lista, que se imprimirá para ver los resultados.\n",
        "\n",
        "NOTA: De aqué en adelante, no se imprimirá todo el corpus para evitar una salida muy grande.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP3NcUan1fX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47202abb-9297-4ff6-bfbf-526d3cf83a9d"
      },
      "source": [
        "#Pasa cada caracter a minuscula \n",
        "pers_min = [w.lower() for w in persuasion] # Cada token del corpus es guardado en minusculas en la lista\n",
        "\n",
        "print(pers_min[:150]) #imprime el corpus en minusculas"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[', 'persuasion', 'by', 'jane', 'austen', '1818', ']', 'chapter', '1', 'sir', 'walter', 'elliot', ',', 'of', 'kellynch', 'hall', ',', 'in', 'somersetshire', ',', 'was', 'a', 'man', 'who', ',', 'for', 'his', 'own', 'amusement', ',', 'never', 'took', 'up', 'any', 'book', 'but', 'the', 'baronetage', ';', 'there', 'he', 'found', 'occupation', 'for', 'an', 'idle', 'hour', ',', 'and', 'consolation', 'in', 'a', 'distressed', 'one', ';', 'there', 'his', 'faculties', 'were', 'roused', 'into', 'admiration', 'and', 'respect', ',', 'by', 'contemplating', 'the', 'limited', 'remnant', 'of', 'the', 'earliest', 'patents', ';', 'there', 'any', 'unwelcome', 'sensations', ',', 'arising', 'from', 'domestic', 'affairs', 'changed', 'naturally', 'into', 'pity', 'and', 'contempt', 'as', 'he', 'turned', 'over', 'the', 'almost', 'endless', 'creations', 'of', 'the', 'last', 'century', ';', 'and', 'there', ',', 'if', 'every', 'other', 'leaf', 'were', 'powerless', ',', 'he', 'could', 'read', 'his', 'own', 'history', 'with', 'an', 'interest', 'which', 'never', 'failed', '.', 'this', 'was', 'the', 'page', 'at', 'which', 'the', 'favourite', 'volume', 'always', 'opened', ':', '\"', 'elliot', 'of', 'kellynch', 'hall', '.', '\"', 'walter', 'elliot', ',', 'born', 'march']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1uFhCMHRPhA"
      },
      "source": [
        "\n",
        "\n",
        "> Una vez teniendo el corpus en minúscula, se puede realizar la limpieza eliminando todos los signos de puntuación, interrogación y admiración, así como los elementos no léxicos. Para realizar esto, se usó la opción ***punctuation*** de la librería ***string***. Esta opción es una cadena de caracteres, que son justo los que buscamos eliminar.\n",
        "\n",
        "\n",
        "> Signos que contiene *punctuation*:\n",
        "   !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "> Con lo anterior, se puede recorrer el corpus y si encuentra alguno de los signos, no lo guardará.\n",
        "Al final, se cuentan los tokens para ver que disminuyeron\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JuPZIATnPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca87e155-6022-46ac-c075-e0c881d7b164"
      },
      "source": [
        "#Introduce cada caracter que sea alfanumérico\n",
        "pers_limpio = [x for x in pers_min if x not in string.punctuation]\n",
        "print(pers_limpio[:150]) #Imprime el resultado sin caracteres no alfanuméricos\n",
        "\n",
        "#Cuenta tokens\n",
        "tokens = len(pers_limpio)\n",
        "print(tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['persuasion', 'by', 'jane', 'austen', '1818', 'chapter', '1', 'sir', 'walter', 'elliot', 'of', 'kellynch', 'hall', 'in', 'somersetshire', 'was', 'a', 'man', 'who', 'for', 'his', 'own', 'amusement', 'never', 'took', 'up', 'any', 'book', 'but', 'the', 'baronetage', 'there', 'he', 'found', 'occupation', 'for', 'an', 'idle', 'hour', 'and', 'consolation', 'in', 'a', 'distressed', 'one', 'there', 'his', 'faculties', 'were', 'roused', 'into', 'admiration', 'and', 'respect', 'by', 'contemplating', 'the', 'limited', 'remnant', 'of', 'the', 'earliest', 'patents', 'there', 'any', 'unwelcome', 'sensations', 'arising', 'from', 'domestic', 'affairs', 'changed', 'naturally', 'into', 'pity', 'and', 'contempt', 'as', 'he', 'turned', 'over', 'the', 'almost', 'endless', 'creations', 'of', 'the', 'last', 'century', 'and', 'there', 'if', 'every', 'other', 'leaf', 'were', 'powerless', 'he', 'could', 'read', 'his', 'own', 'history', 'with', 'an', 'interest', 'which', 'never', 'failed', 'this', 'was', 'the', 'page', 'at', 'which', 'the', 'favourite', 'volume', 'always', 'opened', 'elliot', 'of', 'kellynch', 'hall', 'walter', 'elliot', 'born', 'march', '1', '1760', 'married', 'july', '15', '1784', 'elizabeth', 'daughter', 'of', 'james', 'stevenson', 'esq', 'of', 'south', 'park', 'in', 'the', 'county', 'of', 'gloucester', 'by', 'which']\n",
            "85075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc03jCP7PNAP"
      },
      "source": [
        "> En el paso anterior se hace la eliminación de token no alfanuméricos, sin embargo, es ese paso sólo se elimina si el token tiene un solo elemento, por ejemplo: ')', ',','.', etc. Sin embargo, si existen token que tengan al final o en medio alguno de estos signos, no se eliminará, podríamos encontrar tokens como: '.--', '...', 'hola!', 'como?' 'd.c', etc.\n",
        "\n",
        "> Para resolver lo anterior se realiza otro recorrido al corpus, en donde se analza cada token, y si en ese token se encuentra alguno de los signos no deseados se liminará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMBHR962ELBP",
        "outputId": "160a50bc-9805-471c-8d73-92a467ac1743"
      },
      "source": [
        "pers_limpio2 = [] # Guardará el corpus completamente limpio\n",
        "\n",
        "for token in pers_limpio: #Recorre el corpus\n",
        "  newStr='' # Para ir guardando el token temporal\n",
        "  for letter in token: # Recorre cada caracter del token\n",
        "    if letter in string.punctuation: # Si el caracter es de los no deseados\n",
        "      new = letter.replace(letter,'') #Se elimina el token\n",
        "      newStr=newStr + new # Token temporal sin signo\n",
        "    else:  # Si es un caracter alfanumérico\n",
        "      newStr = newStr + letter # Token temporal\n",
        "  \n",
        "  if newStr != '': # Si el token resultante no es vacío\n",
        "    pers_limpio2.append(newStr) #Se guarda\n",
        "  else: # Si el token resultante es vacío\n",
        "    continue #No lo guarda y continúa con el siguiente token\n",
        "\n",
        "print (pers_limpio2[:150]) #Imprime el corpus completamente limpio\n",
        " #Cuenta total de tokens\n",
        "tokens = len(pers_limpio2)\n",
        "print(tokens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['persuasion', 'by', 'jane', 'austen', '1818', 'chapter', '1', 'sir', 'walter', 'elliot', 'of', 'kellynch', 'hall', 'in', 'somersetshire', 'was', 'a', 'man', 'who', 'for', 'his', 'own', 'amusement', 'never', 'took', 'up', 'any', 'book', 'but', 'the', 'baronetage', 'there', 'he', 'found', 'occupation', 'for', 'an', 'idle', 'hour', 'and', 'consolation', 'in', 'a', 'distressed', 'one', 'there', 'his', 'faculties', 'were', 'roused', 'into', 'admiration', 'and', 'respect', 'by', 'contemplating', 'the', 'limited', 'remnant', 'of', 'the', 'earliest', 'patents', 'there', 'any', 'unwelcome', 'sensations', 'arising', 'from', 'domestic', 'affairs', 'changed', 'naturally', 'into', 'pity', 'and', 'contempt', 'as', 'he', 'turned', 'over', 'the', 'almost', 'endless', 'creations', 'of', 'the', 'last', 'century', 'and', 'there', 'if', 'every', 'other', 'leaf', 'were', 'powerless', 'he', 'could', 'read', 'his', 'own', 'history', 'with', 'an', 'interest', 'which', 'never', 'failed', 'this', 'was', 'the', 'page', 'at', 'which', 'the', 'favourite', 'volume', 'always', 'opened', 'elliot', 'of', 'kellynch', 'hall', 'walter', 'elliot', 'born', 'march', '1', '1760', 'married', 'july', '15', '1784', 'elizabeth', 'daughter', 'of', 'james', 'stevenson', 'esq', 'of', 'south', 'park', 'in', 'the', 'county', 'of', 'gloucester', 'by', 'which']\n",
            "84167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnW6piHSX1gp"
      },
      "source": [
        "3. **Eliminar las stopwords (se puede utilizar listas pre-hechas como las de\n",
        "nltk).**\n",
        "\n",
        "> Para comenzar este punto se descarga la lista de stopwords que proporciona nltk, después se guarda en una lista los stopwors en inglés (porque el texto escogido está en ese idioma)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqbUPsAdz3fD",
        "outputId": "9ba0f6af-058f-4a27-d408-8dcabfdfa015"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t98DoUfkxQpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2e1e80-dccd-4d75-f05e-b3a405ecc511"
      },
      "source": [
        "#Se guarda en la lista los stopwords en inglés\n",
        "stopwords_eng = stopwords.words('english')\n",
        "#Imprime los stopwords\n",
        "print(stopwords_eng)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbINtjuoaS-c"
      },
      "source": [
        "> Una vez teniendo la lista de stopwords, se hace una comparación elemento a elemento con el corpus limpio (pers_limpio) y si no es un stopword (stopwords_eng), se mantiene.\n",
        "\n",
        "> Para ver la diferencia con el corpus original, se realiza el conteo de tokes, se verá que estos disminuyeron de forma considerable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsC6vF-UUnG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f76bfb8-fdb7-4ad4-acc5-a8f2dc071d6f"
      },
      "source": [
        "#Aquí se guardará los elementos que no sean stopwords\n",
        "pers_stopw = [i for i in pers_limpio2 if i not in stopwords_eng]\n",
        "\n",
        "print (pers_stopw[:150]) #Imprime corpus sin stopwords\n",
        "\n",
        "#Cuenta tokens\n",
        "tokens = len(pers_stopw)\n",
        "print(tokens)\n",
        "\n",
        "for token in pers_stopw:\n",
        "  if token == '':\n",
        "    print(token)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['persuasion', 'jane', 'austen', '1818', 'chapter', '1', 'sir', 'walter', 'elliot', 'kellynch', 'hall', 'somersetshire', 'man', 'amusement', 'never', 'took', 'book', 'baronetage', 'found', 'occupation', 'idle', 'hour', 'consolation', 'distressed', 'one', 'faculties', 'roused', 'admiration', 'respect', 'contemplating', 'limited', 'remnant', 'earliest', 'patents', 'unwelcome', 'sensations', 'arising', 'domestic', 'affairs', 'changed', 'naturally', 'pity', 'contempt', 'turned', 'almost', 'endless', 'creations', 'last', 'century', 'every', 'leaf', 'powerless', 'could', 'read', 'history', 'interest', 'never', 'failed', 'page', 'favourite', 'volume', 'always', 'opened', 'elliot', 'kellynch', 'hall', 'walter', 'elliot', 'born', 'march', '1', '1760', 'married', 'july', '15', '1784', 'elizabeth', 'daughter', 'james', 'stevenson', 'esq', 'south', 'park', 'county', 'gloucester', 'lady', 'died', '1800', 'issue', 'elizabeth', 'born', 'june', '1', '1785', 'anne', 'born', 'august', '9', '1787', 'still', 'born', 'son', 'november', '5', '1789', 'mary', 'born', 'november', '20', '1791', 'precisely', 'paragraph', 'originally', 'stood', 'printer', 'hands', 'sir', 'walter', 'improved', 'adding', 'information', 'family', 'words', 'date', 'mary', 'birth', 'married', 'december', '16', '1810', 'charles', 'son', 'heir', 'charles', 'musgrove', 'esq', 'uppercross', 'county', 'somerset', 'inserting', 'accurately', 'day', 'month', 'lost', 'wife', 'followed', 'history', 'rise', 'ancient', 'respectable']\n",
            "38383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqL-UfQVgYnm"
      },
      "source": [
        "4. **Aplicar un algoritmo de Stemming a los tokens limpios (p. ej. el algoritmo\n",
        "de Porter).**\n",
        "\n",
        "> Para este ejercicio se ha decidido realizar el algoritmo de Porter Stemmer. A continuación se explicará paso a paso la implementación de dicho algoritmo. Para lograr llegar a un buen resultado se tomó en cuenta las reglas especificadas en el algoritmo. Las reglas que se mencionarán son las mismas que se encuentran documentadas en la siguiente liga:\n",
        "\n",
        "*Fuente:* [The English (Porter2) stemming algorithm](https://snowballstem.org/algorithms/english/stemmer.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZc9JAi5cnhK"
      },
      "source": [
        "> Pasos previos\n",
        "\n",
        "> Para empezar a desarrollar el algoritmo se debe tomar en cuenta las vocales, los pares de consonantes válidos, y algunas terminaciones de una sola consonante válidas. Para esto, se declararon tres listas con cada uno de los elementos mencionados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprbBpq69zzB"
      },
      "source": [
        "#Contiene las vocales y la 'y'\n",
        "vowel = ['a','e','i','o','u','y']\n",
        "#Contiene los pares de consonantes válidos\n",
        "double = ['bb','dd','ff','gg','mm','nn','pp','rr','tt']\n",
        "#Contiene las terminaciones válidas de una sola consonante\n",
        "validTerm = ['c','d','e','g','h','k','m','n','r','t']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFH35jjZZQ6B"
      },
      "source": [
        "> Para este algoritmo hay que tomar en cuenta que existen palabras cortas (short word) o sílabas cortas (short syllable). Estas sílabas se pueden identificar por: \n",
        "\n",
        "> *'Una vocal seguida por un no-vocal distinta de w, x o Y y precedido por un no vocal'*\n",
        "\n",
        "> Con lo anterior, se puede realizar una función que verifique lo antes mencionado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2G58YvHzsOa"
      },
      "source": [
        "#Funcion que recibe una cadena y verifica si es una palabra corta\n",
        "def CVC(string):\n",
        "    #   verifica Consonante            seguido de Vocal           Seguido de Consonante  que no sea w, x o y      \n",
        "    if string[-3:-2] not in vowel and string[-2:-1] in vowel and string[-1:] not in vowel and string[-1:] not in ['x','w','y']:\n",
        "        return True #Si es palabra corta\n",
        "    else:\n",
        "        return False #Si no es palabra corta"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJOb2ZZ2bfHX"
      },
      "source": [
        "> El algoritmo de Porter se caracterisa por la definición de regiones, que son:\n",
        "\n",
        "> *   *R1: es la región después de la primera no vocal que sigue a una vocal, o el final de la palabra si no existe tal no vocal*\n",
        "*   *R2: es la región después de la primera no vocal que sigue a una vocal en R1, o el final de la palabra si no existe tal no vocal.*\n",
        "\n",
        "> Para simplificar esta parte, se realizó una función que se encarge de contar cuantas vocales seguidas de no vocales existen en la cadena que reciba. Esto servira para cuando se requiera hacer uso de las regiones.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQg_-31clZY"
      },
      "source": [
        "#Cuenta las veces que hay una secuencia vocal consonante\n",
        "def contVC(string):\n",
        "    m = 0 #Guardará el resultado de Vocal-Consonante\n",
        "    vCheck = False #Bandera para cuando se tenga vocal\n",
        "    yCheck = \"\"\n",
        "    for i in range(len(string)): #Ciclo del tamaño de la cadena\n",
        "        if string[i] in vowel: # si la letra es una vocal\n",
        "            # Si (letra es diferente de 'y' y no es vocal) o letra no es 'y'\n",
        "            if (string[i] == 'y' and yCheck not in vowel) or string[i] != 'y':\n",
        "                vCheck = True #Cambia bandera\n",
        "            continue\n",
        "        elif string[i] not in vowel: #Si es consonante\n",
        "            if vCheck == True: #Si se tenía vocal\n",
        "                m += 1 # Se tiene VC\n",
        "                vCheck = False #Cambia bandera\n",
        "        else:\n",
        "            m = 0 #Si no se tiene ningun par VC\n",
        "        \n",
        "        yCheck = string[i] #Guarda la letra visitada para verificar la siguiente\n",
        "    return m  # Regresa el número de pares VC"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3cQUeQhgjZV"
      },
      "source": [
        "> Una vez realizadas las funciones para verificación, y las declaraciones previas, se puede comenzar con los pasos del algoritmo. Para comenzar, se debe realizar el ***paso 0***, este paso consiste revisar la palabra y si tiene alguno de los sufijos ' o 's o 's', se deberá eliminar.\n",
        "\n",
        "> Para realizar el Paso 0, se creo una función llamada **step0**, que recibe una cadena. Los sufijos 's y 's' se guardan en una lista, que se recorre para ver si la cadena termina con alguno de estos sufijos, de ser así se elimina.\n",
        "\n",
        "> Por otro lado, se busca si en la cadena existe un apóstrofe, si es así, se elimina.\n",
        "\n",
        "NOTA: Este paso puede omitirse debido a que ya se realizó la limpieza del corpus, sin embargo se agrega para ver la forma de implementarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l80jB1TuUh5Q"
      },
      "source": [
        "#Función que realiza el paso 0\n",
        "def step0(string):\n",
        "  suffixes = [\"'s\",\"'s'\"] #Lista con sufijos\n",
        "  newStr =\"\" #Guardará la cadena sin sufijo\n",
        "  tam = len(suffixes)\n",
        "  if contVC(string[:-tam])>0:\n",
        "    for suffix in suffixes: #Para cada uno de los sufijos\n",
        "      if string.endswith(suffix): # Si la cadena termina con el sufijo actual\n",
        "        newStr = string.replace(suffix,'') #Se elimina el sufijo\n",
        "        break\n",
        "      else:\n",
        "        newStr = string #Si no termina con el sufijo se queda igual\n",
        "\n",
        "    for letter in newStr: #Para cada letra de la cadena obtenida \n",
        "      if letter == \"'\": #Si se encuentra un apóstrofe\n",
        "        return newStr.replace(letter,'') #Se elimina el apóstrofe\n",
        "  else:\n",
        "     return string\n",
        "  return newStr #Regresa la cadena sin sufijos"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jeqamr7cnK_D"
      },
      "source": [
        "> El siguiente paso es el ***Paso 1a***, este paso toma en cuenta algunos sufijos:\n",
        "\n",
        "> 1. Si encuentra **sses** lo reemplaza por **ss**\n",
        "2. Si encuentra **ied** o **ies** lo reemplaza por **i** si antes hay más de una letra, de lo contrario lo reemplaza por **ie**.\n",
        "3. Si encuentra **s** la elimina si la parte anterior de la palabra tiene una vocal no junta al sufijo, de lo contrario se mantiene.\n",
        "4. Si encuentra **us** o **ss**, se mantiene.\n",
        "\n",
        "> Los pasos anteriores se definieron en la función llamada **step1a**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqLMoJNCIrLE"
      },
      "source": [
        "#Realiza el paso 1a, recibe una cadena\n",
        "def step1a(string):\n",
        "\n",
        "    if len(string) > 3: #Si la cadena no es muy corta\n",
        "        if string.endswith(\"sses\") and contVC(string[:-4]) > 0: # Si termina con sses\n",
        "            return string[:-4]+\"ss\" # Realiza acción 1\n",
        "        elif string.endswith(\"ies\") or string.endswith(\"ied\") : # Si termina con ies\n",
        "          if contVC(string[:-3]) > 0 and len(string)-3 > 1:  # Realiza acción 2\n",
        "            return string[:-3]+\"i\"\n",
        "          else:\n",
        "            return string[:-3]+\"ie\"\n",
        "        elif string.endswith(\"ss\") or string.endswith(\"us\"): # Si termina con ss o us\n",
        "            return string  # Realiza acción 4\n",
        "        elif string.endswith(\"s\") and contVC(string[:-1]) > 0: # Si termina con s\n",
        "          # Verifica que la letra antes de la s no sea vocal y que se tenga una vocal en el resto\n",
        "          if string[-2:-1] not in vowel and re.search('[aeiou]',string[:-1]) != None: # Realiza acción 3\n",
        "            string = string[:-1]+\"\"\n",
        "            return string\n",
        "          else:\n",
        "            return string \n",
        "        else:\n",
        "            return string # Cadena si no cumple ninguna condició del paso 1a\n",
        "    else:\n",
        "         return string # Cadena si es una palabra corta"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SlDg-2et_QL"
      },
      "source": [
        "> El siguiente paso es el **Paso 1b**, en el que se buscan otros sufijos\n",
        "\n",
        "> 1. Si encuentra **eed** o **eedly** lo reemplaza por **ee** si el sufijo está en la region 1 (R1).\n",
        "2. Si encuentra **ed**, **edly, ing** o **ingly** lo elimina si la parte restante contiene una vocal.\n",
        "\n",
        "> Después de la eliminación se realizan otras modificaciones:\n",
        "\n",
        "> 1. Si la cadena termina con **at, bl** o **iz** se agrega una **e**\n",
        "2. Si la cadena termina con un elemento de la lista doble, elimina la última letra.\n",
        "3. Si la palabra es corta, agrega **e**.\n",
        "\n",
        "> Algunas consideraciones a tomar en cuenta para realizar este paso son:\n",
        "\n",
        "> *   - Para verificar la región 1 basta con mandar a llamar la función que cuenta VC (contVC) con la cadena sin el sufijo y si el resultado es mayor a 0 significa que el sufijo pertenece a R1.\n",
        "*   - Para verificar si la palabra es corta, se manda a llamar a la función CVC. \n",
        "\n",
        "> Todas las acciones mencionadas anteriormente se encuentran en la función **step1b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFk-swzNIpv"
      },
      "source": [
        "# Realiza paso 1b, recibe una cadena\n",
        "def step1b(string):\n",
        "    newString = \"\"\n",
        "    substr    = \"\"\n",
        "    if string.endswith(\"eed\") and contVC(string[:-3]) > 0: #Se asegura que la terminacion esté dentro de R1\n",
        "        substr = string[:-4]+\"ee\" # Realiza acción 1 con eed\n",
        "    elif string.endswith(\"eedly\") and contVC(string[:-5]) > 0: # Realiza acción 1 con eedly\n",
        "        substr = string[:-5]+\"ee\"\n",
        "    #Busca que se tenga por lo menos una vocal\n",
        "    elif string.endswith(\"ed\") and re.search('[aeiou]',string[:-2]) != None: # Realiza acción 2 con ed\n",
        "        substr = string[:-2]\n",
        "    #Busca que se tenga por lo menos una vocal\n",
        "    elif string.endswith(\"edly\") and re.search('[aeiou]',string[:-4]) != None: #Realiza acción 2 con edly\n",
        "        substr = string[:-4]\n",
        "    #Busca que se tenga por lo menos una vocal\n",
        "    elif string.endswith(\"ing\") and re.search('[aeiou]',string[:-3]) != None: #Realiza acción 2 con ing\n",
        "        substr = string[:-3]\n",
        "    #Busca que se tenga por lo menos una vocal\n",
        "    elif string.endswith(\"ingly\") and re.search('[aeiou]',string[:-5]) != None: #Realiza acción 2 con ingly\n",
        "        substr = string[:-5]\n",
        "    else:\n",
        "        substr = string # Si no contiene ningun sufijo de este paso\n",
        "    \n",
        "    if len(substr) > 0:\n",
        "        if (substr[-2:] in ['at','bl','iz']):\n",
        "          newString = substr + \"e\"\n",
        "        elif (substr[-2:] in double):\n",
        "          newString = substr[:-1]\n",
        "\n",
        "    if CVC(substr) == True: #CVC\n",
        "       newString = substr+\"e\"\n",
        "    else:\n",
        "       newString = substr\n",
        "\n",
        "    return newString"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqEN4fjlzRAk"
      },
      "source": [
        "> A continuación se debe realizar el **Paso 1c**. Este paso se encarga de reemplayar la **y** por **i** si inmediatamente antes del sufijo no hay una vocal y si esa letra no es la primera de la cadena.\n",
        "\n",
        "> Este paso se realizó con la función llamada **step1c**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkSd0YPt-n4R"
      },
      "source": [
        "# Realiza paso 1c, recibe una cadena\n",
        "def step1c(string):\n",
        "    if string.endswith(\"y\"): # Si termina con y\n",
        "      if string[-2:-1] not in vowel and string.find(string[-2:-1]) != 0: #Verifica que no sea una vocal y no sea la primera\n",
        "        return string[:-1] + \"i\" #Reemplaza y por i\n",
        "      else:\n",
        "        return string # Si la cadena no cumple las características de reemplazo, se mantiene\n",
        "    else:\n",
        "        return string # Si la cadena no termina con y, se mantiene igual"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTFeKf3P0xKn"
      },
      "source": [
        "> En seguida se debe realizar el **Paso 2**. Este paso básicamente se encarga de reemplazar algunos sufijos si se encuentran en R1. En la siguiente lista se muestran los sufijos y por lo que se reemplaza (sufijo ---> reemplazo)\n",
        "\n",
        "> *   tional --- > tion\n",
        "*   enci ---> ence\n",
        "*   anci ---> ance\n",
        "*   abli ---> able\n",
        "*   entli ---> ent\n",
        "*   izer, ization ---> ize\n",
        "*   ational, ation,ator ---> ate\n",
        "*   alism, aliti, alli ---> al\n",
        "*   fulness ---> ful\n",
        "*   ousli, ousness ---> ous\n",
        "*   iveness, iviti ---> ive\n",
        "*   biliti,bli ---> ble\n",
        "*   ogi ---> og  *si la precede una l*\n",
        "*   fulli ---> ful\n",
        "*   lessli ---> less\n",
        "*   li ---> *se elimina si la precede un elemento de la lista validTerm*\n",
        "\n",
        "> Para no realizar reemplazo por cada sufijo como en los pasos anteriores, se guardaron en un diccionario, que será recorrido y si la cadena termina con alguno de estos elementos, se reemplazará por el valor correspondiente.\n",
        "\n",
        "> Para verificar que se encuentren en R1, se manda a llamar la funcion contVC con la cadena sin el sufijo, el valor que entrege debe ser mayor a 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oywfXo8D3uL"
      },
      "source": [
        "def step2(string):\n",
        "    newStr = string # Guardará la cadena final\n",
        "    \n",
        "    #Diccionario con sufijos y reemplazos\n",
        "    suffixes ={'tional':'tion','enci':'ence','anci':'ance','abli':'able','entli':'ent', \n",
        "               'izer':'ize','ational':'ate','ation':'ate','ator':'ate','alism':'al',\n",
        "               'aliti':'al','alli':'al','fulness':'ful','ousli':'ous','ousness':'ous',\n",
        "               'iveness':'ive','iviti':'ive','biliti':'ble','bli':'ble','fulli':'ful',\n",
        "               'lessli':'less','ogi':'og','li':''\n",
        "    }\n",
        "\n",
        "    #Recorre el diccionario\n",
        "    for suffix in suffixes:\n",
        "      tam = len(suffix)\n",
        "      VC = contVC(string[:-tam]) # Cuenta VC\n",
        "      if VC > 0: #Verifica R1\n",
        "        if string.endswith(suffix): #Si la cadena termina con el sufijo\n",
        "          if suffix == 'ogi': # Realiza verificaciones si el sufijo es ogi\n",
        "            if string[-4:-3] == 'l':\n",
        "              newStr = string.replace(suffix,suffixes[suffix]) # Hace reemplazo\n",
        "              break\n",
        "            else:\n",
        "              newStr = string # Si no cumple condiciones de ogi, se mantiene\n",
        "          elif suffix == 'li': # Realiza verificaciones si el sufijo es li\n",
        "            if string[-3:-2] in validTerm:\n",
        "              newStr = string[:-2] # Hace reemplazo\n",
        "              break\n",
        "          else:\n",
        "              newStr = string.replace(suffix,suffixes[suffix]) # Reemplazo para cualquier otro sufijo\n",
        "        else:\n",
        "          continue\n",
        "    return newStr "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkpA3S95WIo"
      },
      "source": [
        "> Para el siguiente paso, que es el **Paso 3**, se hacen reempazos para otros sufijos, que deben estar en R1, estos son:\n",
        "\n",
        "> *   tional ---> tion\n",
        "*   ational ---> ate\n",
        "*   alize ---> al\n",
        "*   icate, iciti, ical ---> ic\n",
        "*   ful, ness ---> se eliminan\n",
        "*   ative ---> Se elimina si está en R2\n",
        "\n",
        "> Para este paso se utilizó la misma estrategia que en el paso 2, se guardaron los sufijos en un diccionario y se realizan los reemplasos. Para hacer la verificación de R2, se manda a llamar a *contVC* con la cadena sin el sufijo, en este caso, el resultado debe ser mayor a 1.\n",
        "\n",
        "> Los pasos necesarios se colocaron en la función **step3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdW0cfxxXms4"
      },
      "source": [
        "#Realiza paso 3, recibe una cadena\n",
        "def step3(string):\n",
        "    newStr = string #Guardará la cadena final\n",
        "    #Diccionario con sufijos y reemplazos\n",
        "    suffixes = {'tional':'tion','ational':'ate','alize':'al','icate':'ic',\n",
        "                   'iciti':'ic', 'ical':'ic', 'ful':'','ness':'','ative':''                       \n",
        "    }\n",
        "    \n",
        "    #Recorre el diccionario\n",
        "    for suffix in suffixes:\n",
        "      tam = len(suffix) # obtiene el tamaño del sufijo\n",
        "      VC = contVC(string[:-tam]) # Obtiene el total de VC\n",
        "      if string.endswith(suffix) and suffix != 'ative': #Si la cadena termina con un sufijo que no sea ative\n",
        "        if VC > 0: #en region 1\n",
        "          newStr = string.replace(suffix,suffixes[suffix]) #Realiza reemplazo\n",
        "          break\n",
        "      elif string.endswith(suffix) and suffix == 'ative':  #Si la cadena termina con el sufijo ative\n",
        "        if VC > 1: #En region 2\n",
        "          newStr = string.replace(suffix,suffixes[suffix]) #Realiza reemplazo\n",
        "          break\n",
        "    return newStr #Regresa cadena final"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnjNEBJ-5U8"
      },
      "source": [
        "> En el **Paso 4** se tiene dos opciones:\n",
        "1. busca entre los sufijos y si están en R1 se realiza se elimina. Los sufijos son: *al, ance, ence, er, ic, able, ible, ant, ement, ment, ent, ism, ate, iti,ous, ive, ize*\n",
        "2. Si se encuentra el sufijo **ion**, se elimina si antes de este hay una **s** o una **t**\n",
        "\n",
        "> En esta ocasión se realizó la función **step4**, que recibe una cadena. Los sufijos se colocaron en una lista, debido a que no hay reemplazon, dicha lista se recorre y se realizan las verificaciones necesarias.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHdDTfdQrO1r"
      },
      "source": [
        "# Realiza el paso 4, recibe una cadena\n",
        "def step4(string):\n",
        "    newStr = string #Guardará la cadena final\n",
        "    #Lista con sufijos\n",
        "    suffixes =['al','ance','ence','er','ic','able','ible','ant',\n",
        "                   'ement','ment','ent','ism','ate','iti','ous','ive','ize','ion']\n",
        "    \n",
        "    # Recorre lista\n",
        "    for suffix in suffixes:\n",
        "      tam = len(suffix) #Tamaño del sufijo\n",
        "      VC = contVC(string[:-tam]) # Cantidad de VC\n",
        "      if string.endswith(suffix): #Si la cadena termina con el sufijo\n",
        "        if VC > 1: # Si está en R1\n",
        "          if suffix != 'ion': # Cualquier sufijo menos ion\n",
        "            newStr = string[:-tam] #Elimina sufijo\n",
        "            break\n",
        "          else:\n",
        "            if string[-(tam+1):-tam] in ['s','t']: #Verificaciones para sufijo ion\n",
        "              newStr = string[:-tam] #Elima sufijo\n",
        "              break\n",
        "      else:\n",
        "        continue \n",
        "\n",
        "    return newStr"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8V4R8LKBb5f"
      },
      "source": [
        "> El último paso es el **Paso 5**. Aquí también se tienen sólo dos opciones:\n",
        "1. Si encuentra sufijo **e** se elimina si está en R2 o si está en R1 y no hay antes una sílaba corta.\n",
        "2. Si encuentra sufijo **l** se elimina si está en R2 y la precede una *l*\n",
        "\n",
        "> Para este último paso se realizó la función **step5**, que recibe una cadena. Se hacen las verificaciones necesarias para cada opción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fqrsY5gwY6G"
      },
      "source": [
        "# Realiza paso 5, recibe una cadena\n",
        "def step5(string):\n",
        "    #Cuenta VC sin sufijo\n",
        "    VC = contVC(string[:-1]) # Obtiene cantidad de VC\n",
        "    # Si la string termina con 'e' y está en R2  o está en R1 y no es sílaba corta\n",
        "    if string.endswith('e') and ((VC > 1) or (VC == 1 and CVC(string[:-1]) == False)):\n",
        "        return string[:-1] #Elimina e\n",
        "    #Si string termina con 'l', está en R2 y la precede una 'l'\n",
        "    elif string.endswith('l') and VC > 1 and string[-2:-1] == 'l':\n",
        "        return string[:-1] #Elimina l\n",
        "    else:\n",
        "        return string "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbhZQNsGD0Xl"
      },
      "source": [
        "> Finalmente, se realizó la función getStem, que recibe la cadena a la que se le aplicarán todos los pasos. Dentro de esta función se manda a llamar uno a uno los pasos. Regresa la cadena después de haberle aplicado cada función."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBOJwdcLUJql"
      },
      "source": [
        "#Realiza todos los pasos, recibe una cadena\n",
        "def getStem(word) :\n",
        "    s0  = step0(word) #Paso 0 con string\n",
        "    s1a = step1a(s0) #Paso 1a con s0\n",
        "    s1b = step1b(s1a) #Paso 1b con s1a\n",
        "    s1c = step1c(s1b) #Paso 1c con s1b \n",
        "    s2 = step2(s1c) #Paso 2 con s1c\n",
        "    s3 = step3(s2)  #Paso 3 con s2\n",
        "    s4 = step4(s3)  #Paso 4 con s3\n",
        "    s5 = step5(s4) ##Paso 5 con s4\n",
        "        \n",
        "    return s5"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR89ZHHPFTKB"
      },
      "source": [
        "> Para poder aplicar el algoritmo al corpus que se está analizando se realizan los siguientes pasos:\n",
        "1. Se crea una lista vacía (pers_final) para guardar los tokens\n",
        "2. Se recorre cada token del corpus\n",
        "3. Cada token se pasa a la función getStem y el resultado se inserta en la lista.\n",
        "4. Se imprime el corpus final "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryD_-Z_Ome0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6325a03a-a44b-49bd-851f-1a41ad75c6c9"
      },
      "source": [
        "pers_final =[] #Lista vacía para resultados\n",
        "for word in pers_stopw: # Recorre corpus\n",
        "  token = getStem(word) # Se obtiene el stem para cada elemento del corpus \n",
        "  pers_final.append(token) #Se inserta el resultado del paso anterior en la lista\n",
        "\n",
        "#Se imprime el corpus resultante\n",
        "print (pers_final[:150])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['persuas', 'jane', 'austen', '1818', 'chapter', '1', 'sire', 'walter', 'elliot', 'kellynch', 'hall', 'somersetshir', 'mane', 'amus', 'never', 'took', 'book', 'baronetag', 'found', 'occup', 'idl', 'hour', 'consol', 'distress', 'one', 'faculti', 'rous', 'admir', 'respect', 'contempl', 'limit', 'remnant', 'earliest', 'patent', 'unwelcom', 'sensat', 'aris', 'domestic', 'affair', 'chang', 'natur', 'piti', 'contempt', 'turn', 'almost', 'endless', 'creation', 'last', 'centuri', 'everi', 'leaf', 'powerless', 'could', 'read', 'histori', 'interest', 'never', 'fail', 'page', 'favourit', 'volum', 'always', 'open', 'elliot', 'kellynch', 'hall', 'walter', 'elliot', 'born', 'march', '1', '1760', 'marri', 'juli', '15', '1784', 'elizabeth', 'daughter', 'james', 'stevenson', 'esq', 'south', 'park', 'counti', 'gloucester', 'ladi', 'die', '1800', 'issu', 'elizabeth', 'born', 'june', '1', '1785', 'ann', 'born', 'august', '9', '1787', 'still', 'born', 'sone', 'november', '5', '1789', 'mari', 'born', 'november', '20', '1791', 'precis', 'paragraph', 'origin', 'stood', 'printer', 'hand', 'sire', 'walter', 'improv', 'add', 'inform', 'famili', 'word', 'date', 'mari', 'birth', 'marri', 'december', '16', '1810', 'charles', 'sone', 'heir', 'charles', 'musgrov', 'esq', 'uppercross', 'counti', 'somerset', 'insert', 'accur', 'day', 'month', 'lost', 'wife', 'follow', 'histori', 'rise', 'ancient', 'respect']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWhMrBkvGgiT"
      },
      "source": [
        "**5. Obtener las frecuencias de los tipos en el corpus.**\n",
        "\n",
        "> Para resolver esta parte se hace uso de un diccionario vacío. Se recorrerá el corpus token por token, si el token actual se encuentra en el diccionario (lo cual hará que el conteo sea por tipos), se sumará 1 a su valor, de lo contrario, se introducirá en el diccionario.\n",
        "\n",
        "> Se imprimen las frecuencias y el token en forma de lista.\n",
        "\n",
        "> Al final, se suman los valores de cada tipo para verificar que todos los tokens fueron incluidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx3sZ75tcRqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745b531d-0175-41d4-aa82-0144142f271b"
      },
      "source": [
        "freq={} #Diccionario en el que se guardarán las frecuencias\n",
        "for word in pers_final: # Recorre el corpus\n",
        "    if freq.get(word) == None: # Si el tipo aun no está en el diccionario\n",
        "      freq[word] = 1 # Lo agrega y suma 1\n",
        "    else: # Si ya está en el diccionario\n",
        "      freq[word]=freq[word]+1 #Suma 1 a la frecuencia (valor)\n",
        "#Recorre diccionario para imprimir algunas frecuencias por tipos \n",
        "i = 0     \n",
        "for clave in freq.keys(): \n",
        "  if i <= 100:\n",
        "    print(freq[clave],clave)\n",
        "    i += 1\n",
        "  else:\n",
        "    break\n",
        "\n",
        "#Suma las frecuencias para validar resultados\n",
        "tokens=sum(freq.values())\n",
        "print(\"Total de tipos: \", tokens)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 persuas\n",
            "1 jane\n",
            "1 austen\n",
            "1 1818\n",
            "24 chapter\n",
            "3 1\n",
            "149 sire\n",
            "141 walter\n",
            "295 elliot\n",
            "73 kellynch\n",
            "28 hall\n",
            "4 somersetshir\n",
            "134 mane\n",
            "22 amus\n",
            "155 never\n",
            "19 took\n",
            "18 book\n",
            "2 baronetag\n",
            "83 found\n",
            "5 occup\n",
            "3 idl\n",
            "62 hour\n",
            "5 consol\n",
            "26 distress\n",
            "238 one\n",
            "1 faculti\n",
            "11 rous\n",
            "26 admir\n",
            "38 respect\n",
            "8 contempl\n",
            "4 limit\n",
            "1 remnant\n",
            "4 earliest\n",
            "1 patent\n",
            "3 unwelcom\n",
            "14 sensat\n",
            "3 aris\n",
            "11 domestic\n",
            "8 affair\n",
            "43 chang\n",
            "33 natur\n",
            "14 piti\n",
            "6 contempt\n",
            "55 turn\n",
            "60 almost\n",
            "1 endless\n",
            "3 creation\n",
            "92 last\n",
            "1 centuri\n",
            "102 everi\n",
            "1 leaf\n",
            "1 powerless\n",
            "451 could\n",
            "21 read\n",
            "17 histori\n",
            "61 interest\n",
            "15 fail\n",
            "2 page\n",
            "8 favourit\n",
            "4 volum\n",
            "110 always\n",
            "39 open\n",
            "12 born\n",
            "1 march\n",
            "1 1760\n",
            "58 marri\n",
            "2 juli\n",
            "2 15\n",
            "1 1784\n",
            "90 elizabeth\n",
            "33 daughter\n",
            "6 james\n",
            "1 stevenson\n",
            "5 esq\n",
            "2 south\n",
            "4 park\n",
            "4 counti\n",
            "1 gloucester\n",
            "242 ladi\n",
            "8 die\n",
            "1 1800\n",
            "2 issu\n",
            "3 june\n",
            "1 1785\n",
            "497 ann\n",
            "2 august\n",
            "2 9\n",
            "1 1787\n",
            "74 still\n",
            "17 sone\n",
            "9 november\n",
            "3 5\n",
            "1 1789\n",
            "138 mari\n",
            "2 20\n",
            "1 1791\n",
            "6 precis\n",
            "2 paragraph\n",
            "6 origin\n",
            "12 stood\n",
            "1 printer\n",
            "Total de tipos:  38383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH1qv9f3YHGO"
      },
      "source": [
        "**6. Obtener la lista de tipos por orden de frecuencia (de mayor frecuencia a\n",
        "menor frecuencia).**\n",
        "\n",
        "> Para poder hacer este ejercicio se hizo uso de las funciones que ofrecen los diccionarios de python. Se realizó lo siguiente:\n",
        "1.   Se utilizó la opción *items()*, la cual devolverá una lista de tuplas *clave-valor*\n",
        "2.   *x* representa al elemento de la tupla, por lo que *x[0]* representa la clave y *x[1]* el valor.\n",
        "3.   *key=lambda x:x[1]* indica que la clave de comparación es el valor de los elementos del diccionario. Es decir, en este caso, se tomarán las frecuencias para hacer la comparación.\n",
        "4.    Debido a que se solicita hacer el ordenamiento de mayor a menor frecuencia, se agregó el parámetro *reverse=True*, con lo que se indica que los elementos se ordenarán de forma descendente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJQapsA6XtAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab0f5a6-5249-4c85-866d-a55c73a59cf8"
      },
      "source": [
        "#Realiza ordenamiento por frecuencias\n",
        "freqMm = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
        "#Imprime lista con frecuencias parte inicial\n",
        "print(\"Parte inicial: \\n\", freqMm[:150])\n",
        "\n",
        "#Imprime lista con frecuencias última parte\n",
        "print(\"Parte final: \\n\", freqMm[-150:])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parte inicial: \n",
            " [('ann', 497), ('could', 451), ('would', 355), ('captain', 305), ('elliot', 295), ('mrs', 291), ('mr', 256), ('ladi', 242), ('one', 238), ('must', 228), ('wentworth', 218), ('much', 205), ('good', 191), ('think', 183), ('littl', 177), ('said', 173), ('charles', 166), ('might', 166), ('well', 164), ('see', 160), ('feel', 158), ('look', 157), ('never', 155), ('go', 153), ('time', 152), ('sire', 149), ('know', 149), ('russel', 148), ('walter', 141), ('noth', 140), ('mari', 138), ('great', 136), ('mane', 134), ('musgrov', 130), ('miss', 128), ('even', 127), ('seem', 124), ('soon', 122), ('quit', 121), ('friend', 120), ('father', 118), ('say', 118), ('though', 117), ('two', 114), ('first', 113), ('make', 111), ('louisa', 111), ('always', 110), ('use', 109), ('come', 108), ('without', 108), ('bath', 104), ('everi', 102), ('like', 102), ('place', 100), ('thought', 100), ('room', 100), ('sister', 99), ('long', 99), ('give', 98), ('wish', 98), ('made', 97), ('happi', 96), ('hous', 94), ('last', 92), ('elizabeth', 90), ('however', 89), ('talk', 89), ('famili', 88), ('acquaint', 88), ('may', 87), ('better', 87), ('year', 86), ('walk', 86), ('mani', 85), ('young', 84), ('moment', 84), ('found', 83), ('home', 83), ('croft', 82), ('felt', 80), ('want', 79), ('away', 78), ('way', 78), ('ever', 78), ('uppercross', 77), ('day', 77), ('sure', 77), ('present', 76), ('manner', 76), ('take', 75), ('harvill', 75), ('still', 74), ('done', 74), ('henrietta', 74), ('kellynch', 73), ('hope', 73), ('believ', 73), ('upon', 72), ('enough', 71), ('back', 70), ('parti', 70), ('benwick', 70), ('smith', 70), ('admiral', 69), ('mind', 68), ('came', 68), ('woman', 67), ('lyme', 67), ('another', 66), ('return', 66), ('clay', 66), ('consider', 65), ('thing', 65), ('heard', 65), ('someth', 64), ('appear', 63), ('call', 63), ('ine', 63), ('perfect', 63), ('hour', 62), ('interest', 61), ('knew', 61), ('almost', 60), ('rather', 60), ('near', 60), ('half', 60), ('certain', 60), ('mean', 60), ('pass', 59), ('possibl', 59), ('love', 59), ('morn', 59), ('marri', 58), ('dear', 58), ('seen', 58), ('yet', 58), ('leav', 58), ('perhap', 57), ('hear', 57), ('shall', 57), ('live', 56), ('part', 56), ('ohe', 56), ('turn', 55), ('word', 55), ('visit', 55), ('poor', 55), ('together', 54), ('other', 54)]\n",
            "Parte final: \n",
            " [('imit', 1), ('23', 1), ('explanatori', 1), ('sulta', 1), ('scheherazad', 1), ('unfavour', 1), ('strictest', 1), ('injunct', 1), ('plung', 1), ('unsaf', 1), ('unwis', 1), ('thrill', 1), ('denot', 1), ('unfold', 1), ('miniatur', 1), ('paint', 1), ('german', 1), ('artist', 1), ('quiver', 1), ('lipe', 1), ('dote', 1), ('prey', 1), ('frames', 1), ('heaviest', 1), ('robust', 1), ('strive', 1), ('anchorag', 1), ('signal', 1), ('vers', 1), ('proverb', 1), ('fickl', 1), ('watches', 1), ('calculates', 1), ('wing', 1), ('treasures', 1), ('forbid', 1), ('undervalu', 1), ('faithful', 1), ('enviabl', 1), ('covet', 1), ('longest', 1), ('seal', 1), ('closer', 1), ('footstep', 1), ('revolut', 1), ('legibl', 1), ('e', 1), ('devour', 1), ('broke', 1), ('resentful', 1), ('undeviat', 1), ('f', 1), ('hither', 1), ('tranquil', 1), ('distract', 1), ('precaut', 1), ('prophesi', 1), ('mischanc', 1), ('damp', 1), ('ungrateful', 1), ('gunsmith', 1), ('familiar', 1), ('pale', 1), ('movem', 1), ('unpack', 1), ('barrel', 1), ('raptur', 1), ('gravel', 1), ('immort', 1), ('slowli', 1), ('saunter', 1), ('politician', 1), ('housekeeper', 1), ('flirt', 1), ('retrospect', 1), ('poignant', 1), ('variat', 1), ('today', 1), ('retard', 1), ('vanquish', 1), ('sheet', 1), ('pour', 1), ('supplant', 1), ('sufferer', 1), ('loveliest', 1), ('medium', 1), ('unrival', 1), ('obstinaci', 1), ('exalt', 1), ('mad', 1), ('regain', 1), ('remors', 1), ('grossli', 1), ('abid', 1), ('entangl', 1), ('homag', 1), ('inexpress', 1), ('felicit', 1), ('inact', 1), ('wednesday', 1), ('retain', 1), ('subsequ', 1), ('energi', 1), ('wisher', 1), ('indel', 1), ('incurr', 1), ('overwhelm', 1), ('steadfast', 1), ('assembl', 1), ('mixtur', 1), ('commonplac', 1), ('shorter', 1), ('delici', 1), ('greenhous', 1), ('imparti', 1), ('decides', 1), ('deliber', 1), ('enemi', 1), ('accent', 1), ('crown', 1), ('earn', 1), ('reverses', 1), ('brook', 1), ('24', 1), ('ultim', 1), ('spendthrift', 1), ('daylight', 1), ('ey', 1), ('struggles', 1), ('indic', 1), ('impetuos', 1), ('suaviti', 1), ('niceti', 1), ('instrumental', 1), ('landaulett', 1), ('headship', 1), ('derang', 1), ('discomfit', 1), ('wheedl', 1), ('caress', 1), ('disproport', 1), ('harmoni', 1), ('sourc', 1), ('petti', 1), ('requit', 1), ('acquisit', 1), ('defianc', 1), ('sunshin', 1), ('national', 1), ('finis', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WH5Syffxw2Y"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "> En la salida anterior se puede observar que los resultados son satisfactorios porque se observa al principio el tipo con mayor frecuencia y van disminuyendo. Este ejercicio fue de gran utilidad porque se pudo ver y practicar el proceso de ánilis de corpus. Es interesante ver que se deben de realizar varias modificaciones para no tener demasiados tipos en el corpus, por lo que obtener el Stem de las palabras resulta de gran utilidad."
      ]
    }
  ]
}